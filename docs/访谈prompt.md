角色:
你是一名资深的研究员,现在你需要往顶级会议CHI上投稿，你已经做了半结构化访谈。

任务:
你的任务是深入分析一份关于AI医疗系统的用户访谈数据，并将其整理成一个清晰的、能够支撑特定研究问题（RQs）的树状（或思维导图）结构。你需要从原始、零散的访谈内容中，提炼出具有逻辑层次的观点和证据。

核心要求:

围绕核心框架：你的所有分析都必须围绕下方“材料二”中提供的三个研究问题（RQ）及其核心发现来组织。

提炼与综合：你需要从访谈数据中挖掘和综合关键主题、普遍情绪和有代表性的观点，而不仅仅是简单地复制粘贴原文。

证据支撑：所有提炼出的观点，都必须附上直接引用的访谈原文作为证据，并清晰地标注出访谈对象ID（例如：(XY-02B)）。

格式清晰：请使用Markdown的层级列表（通过缩进表示）来呈现最终结果，使其结构一目了然，并易于转换成思维导图。

输入材料:

材料一：用户访谈数据
\begin{table}[]
\begin{tabular}{llllllllllllll}
ID     & 科室            & 7、您当前的身份或职称是？  & I01\_系统理解困惑                                                                                                               & I02\_临床工作整合                                                                               & I03\_效率准确性                                                                     & I04\_信任建立时刻                                                                                                                         & I05\_动态轨迹价值                                                                                                                                                                           & I06\_个体化分析交互                                                                                                & I07\_人群分析价值                                                                                               & I08\_LLM建议质量                                                                                                                           & I09\_AI临床差异                                                                                                                       & I10\_新风险发现                                                                                     & I11\_改进建议                                                                                                                                                                                                                                                             \\
XY-01A & XY-Nephrology & 副主任医师          &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                       \\
XY-02B & XY-Nephrology & 其他（请注明）〖护理〗    & 整体很容易理解，没有感到困惑的地方。                                                                                                        & 会在查房、随访的时候使用。可以直接展示给病人看，让他们直观地了解自己接下来最需要注意的方面，相当于敲响一个“小警钟”。                               & 能提升效率和准确率。系统展示的方式非常直观。相比医生口头叙述可能会遗漏某些方面，让病人直接看这个界面，他能马上知道所有需要重点关注的板块，信息传递更全面。  & 当看到系统是将各个风险因素都综合考虑进来，并结合在一起进行整体分析时，会觉得它是可信的。这比医生有时只关注某一个孤立的指标要更全面。                                                                  & （访谈对象指出功能限制）目前的可视化图表很好，但主要展示的是化验室指标。如果能将患者的其他并发症（如心脑血管疾病、合并症等）也整合进来，对病情的整体理解会更有帮助，因为这些因素对患者的整体风险影响很大。                                                                                 & （访谈对象再次强调数据全面性）对预测逻辑是信任的，因为它基于后台的各项数据。但目前的指标主要局限于化验室检查，如果能加入更多维度的信息，如患者之前有没有心梗、支架，心功能、心电图、CT等情况，会让模型的预测更完善。 & 肯定有用，不是多余的。群体性的数据比个体数据更有说服力，因为它更能反映一个总体的趋势。                                                               & 感觉大语言模型总结出的内容和系统中的轨迹图所反映的趋势是一致的、合理的。                                                                                                   & 目前没有遇到过不一致的情况，AI的预测和自己的临床判断基本都是一致的。                                                                                               & 带来了启发：系统将各项指标都清晰地展示出来，比医生自己逐个去看指标效率要高很多。但未发现曾忽略的风险因素：因为目前系统里展示的都是临床上非常常规、并且一直都在重点关注的生化指标。      & 界面布局需要优化：问题：当前界面元素太多，显得有些拥挤，最重要的风险曲线图不够突出。建议：应该将动态风险曲线图放大，作为界面的核心和主体。其他具体指标可以先隐藏，当需要查看时再点击弹出。最终的目标是让患者或医生一眼就能看到最核心、最需要注意的信息，重点要非常突出。                                                                                                                                  \\
XY-03A & XY-Nephrology & 主治医师           & 没有困难，很容易理解。                                                                                                               & （此问题在录音中未直接回答，访谈对象的回答跳转到了对系统价值的探讨。）                                                       & 有这个潜力。如果出现AI的预测和医生的预测不一致，而最终患者的结局证明了AI的预测是准确的，那就充分说明了它的价值，也能极大地增强我们对系统的信心。     & 动态的指标曲线对比图很好，能够建立信任。当点击某个时间点，系统能立刻显示出该时刻的所有关键指标数值，这个功能非常有用，让人一目了然，这也会增强信任。                                                          & 会引发我的思考和疑问。如果系统呈现的风险曲线和我的临床判断不一致，我会去深入研究系统关注的那些指标（比如钠离子），查阅相关文献，这会促使我去关注之前可能忽略的方面，从而加深对病情的理解。                                                                                         & -                                                                                                           & 这个功能很好，非常有帮助。它能清晰地告诉我，某个指标在哪个范围内是安全的（绿色），哪个范围是危险的（红色）。如果我的病人的指标落在了危险区，这个图表就为我的治疗提供了明确的目标，即努力将该指标调整到安全区间内。 & 有参考价值。我会先看风险曲线图，然后再看这段文字总结，用来对比系统关注的重点和我自己关注的重点有什么不同。                                                                                  & 有不一致的地方，或者说关注点不同。例如，系统在预测中很关注钠离子和PTH（甲状旁腺激素），但在我的临床实践中，我可能更关注白蛋白、钾和血红蛋白。这种差异是存在的。                                                 & 有，最大的收获就是打开了我的思路。我意识到自己平时关注的指标可能比较局限和固化（“就那几个”）。系统提示我，像钠离子或PTH这类我之前关注较少的指标，对于预测患者死亡风险可能同样至关重要。 & 增加模型预测的“可解释性”。具体建议：当系统判断某个指标（比如“钠”）是关键风险因素时，希望能附上解释和说明，比如提供相关的参考文献或指南作为论证依据。原因：这样不仅能让我们更信服，也能让我们在使用过程中学习和进步，理解模型背后的逻辑。                                                                                                                                                \\
XY-04B & XY-Nephrology & 副主任医师          & 比较容易接受，目前没有发现特别难以理解或令人困惑的部分。                                                                                              & 可以融入日常工作。 比如患者来就诊时，可以将该系统与医院现有系统对接，通过分析患者的化验结果，来查看其死亡风险等预测信息。                             & 认为其准确率应该是相对比较高的。                                                               & 用户表示，对比使用AI前后的工作流程，感觉“差不多”，没有体会到巨大的差异或特定的信任/怀疑时刻。                                                                                   & 认为这些可视化的趋势是有用的。 但其局限性在于无法获取患者在当前医院就诊之前的历史数据，如果能和医院的历史数据系统对接，让信息更完善，效果会更好。                                                                                                             & 此问题在访谈中未明确问及。                                                                                               & 认为对个别病人的诊疗有一定指导作用，但其更大的用处在于进行科研和撰写学术文章。                                                                   & 认为有一定作用，但并非完全准确。 AI的判断会和医生的自身判断存在分歧，比如系统可能会为一个患者提示某个未曾诊断过的疾病风险。                                                                        & 用户在回答上一个问题时提到了判断不一致的情况，例如AI可能会预测出一个患者并未被诊断的疾病风险。                                                                                  & 用户表示对系统的了解还比较少，暂时没有获得这方面的启发。                                                                   & 提出了两点建议：1. 建议系统可以给出诊疗建议，比如当患者指标偏离正常范围时，提示如何让其回归正常范围。 2. 当数据点很多时，风险曲线图可能会变得很复杂，不好判断，建议在后续版本中对图表展示进行优化。                                                                                                                                                                 \\
XY-05A & XY-Nephrology & 主任医师           &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                       \\
XY-06B & XY-Nephrology & 其他（请注明）〖副主任护师〗 & 系统比较容易使用，没有信息过量的问题。 风险分析功能尤其容易理解，且利用价值很大。                                                                                 & 会作为评估病人的辅助工具。 在自己完成初步评估后，会参考系统的“智能洞察”功能，这有助于使最终的评估结果更全面。                                  & “关键特征识别”功能识别出的指标是准确的，但感觉还不够全面。                                                 & 信任：特征分析中的“重要性”评分功能有助于建立信任。它能将风险因素量化（例如，血液透析占9\%权重），这是人工评估难以做到的。 怀疑：对模型识别出的某些关键特征（如尿酸）的权重持怀疑态度，认为模型可能过分强调了它的重要性。                     & 意义比较大。当看到病人风险较高时，系统会提示，并促使去关注其他相关指标。表格形式列出的末次化验数据对了解病人情况也很有用。                                                                                                                         & 此问题在访谈中未明确问及。                                                                                               & 认为此功能肯定有用，但目前自己还不是很熟悉。                                                                                    & 1. 质疑部分关键特征：认为系统识别的关键特征（如尿酸、血液透析）不一定适用于所有病人，对其普适性有疑问。 2. 建议改进：建议“个性化建议”需要有更强的论据支持，例如关联SOP（标准作业程序）或临床指南，以提高其可信度。                        & 会结合使用。先有自己的判断，然后再参考AI的决策，最终的意见会是两者的结合，不会完全只依赖AI。                                                                                  & 有。系统对于“死亡风险”的量化和提示功能很有启发。它能通过曲线直观地展示高风险时期，从而提醒医护人员对特定病人进行更密切的关注，以减少不良事件（如死亡、退出治疗）的发生率。         & 提出了两点建议：1. 增强证据支持：个性化建议部分应加入临床指南或SOP等作为证据支撑，以增强可信度。 2. 优化视觉呈现：在关键特征识别模块，建议用不同颜色或其它方式，将最重要（如占比31\%）的指标高亮标出，使其更醒目。                                                                                                                                                      \\
XY-07A & XY-Nephrology & 住院医师           & 比较好上手，目前没有遇到非常困惑的地方。                                                                                                      & 主要会在腹透门诊随访的场景下应用。                                                                         & 部分可以。                                                                          & 群体性指标分析功能。这个功能可以基于我们医院自己的数据，提炼出一些有临床意义和科研价值的结论（比如某个指标在特定数值范围内的风险变化），这让我觉得系统是可信且有深度的。                                                & 整体风险曲线很重要：代表死亡率的主曲线非常有意义，我会第一时间关注它，用以判断患者未来一年的整体风险，并决定需要给予多高的关注度。其他指标曲线比较杂乱：多条指标曲线叠在一起时，肉眼很难清晰分辨。相比之下，我更倾向于直接看右侧的特征重要性（权重）列表，那个更直观。建议：直接对患者说“死亡率”这个词过于直接，可能会让患者难以接受，建议调整为“风险”等更委婉的表述。 & （访谈对象将此问题与临床关注点结合回答）我会重点关注和点击查看几类关键指标：贫血指标（血红蛋白）、营养状况（白蛋白）、钙磷代谢（钙、磷、PTH）以及心脑血管并发症相关的指标。这些是腹透患者管理的核心。        & 非常有价值，不是多余的。这个功能对于临床和科研的意义都很大，可以帮助我们发现自己中心数据里的规律和趋势，甚至可以从中产生一些科研论文的思路。                                    & 有点冗余，意义不大。它总结出的信息，比如“白蛋白下降提示...”等，都是我们临床医生已经熟知和掌握的内容，没有提供新的洞见。                                                                         & 目前没法判断，因为没有看到患者的最终结局。AI存在局限性：AI的判断基于客观的化验指标，但临床医生的很大一部分判断来自于床边查看患者，观察那些无法被量化的临床体征（如精神状态、水肿情况等细微变化）。这些是模型无法捕捉的，有时这些细微变化恰恰是病情突变的前兆。 & 有启发，主要是“群体性指标分析”功能。这个功能可以提示我们整个患者群体的某些指标规律，这是我们平时单纯看个体报告所无法发现的。                                & “特征分析”模块的交互可以优化，让点击和查看更方便。大语言模型总结部分需要改进，目前提供的信息比较基础，临床价值有限，可以考虑如何让它提供更量化、更有深度的分析。                                                                                                                                                                                     \\
XY-08B & XY-Nephrology & 主任医师           & 没有困难，很容易理解。                                                                                                               & 主要用于门诊病人的随访和住院病人的查房。可以结合模型对病人情况进行分析。                                                      & 能提升效率：可以肯定地增加诊断的效率。准确率有待验证：诊断的准确率需要长期的前瞻性研究来验证。如果未来事实证明模型的预测是准确的，那么它的价值就很大。    & （访谈对象将此问题与验证过程结合）与其说是信任，不如说是一个验证和对比的过程。我会先根据自己的临床经验对化验单进行判断，然后再看模型的图表和结论，验证两者的思路是否吻合。如果长期使用下来，发现模型的预测和我的判断高度吻合，甚至优于我的判断，那么信任就会完全建立。 & -                                                                                                                                                                                     & -                                                                                                           & 非常有价值。我们可以认可通过群体数据分析得出的安全范围。这种功能可以帮助我们发现自己中心数据独有的规律，并与临床指南进行对比，很有意义。                                      & 存在比较大的问题，甚至有逻辑矛盾。问题1：内容重复：感觉每个病人的文字总结都差不多，反复提及“白蛋白、尿酸、消化系统疾病”。问题2：逻辑矛盾：模型多次强调“消化系统疾病”是重要风险因素，但在特征分析的详细数据里，该项指标的数值一直都是“0”，这让人无法理解其判断依据。 & 有，主要体现在关注点的不同上。AI模型似乎非常关注“消化系统疾病”和“尿酸”，而作为临床医生，我可能根本不会关注这两个点，因为它们的特异性不强。                                                          & 有启发。例如模型一直强调尿酸的重要性，而这确实是我平时不太会重点关注的指标，这引发了我的思考。                                                & 核心诉求：增强可解释性，提供证据。具体建议1：当模型给出一个结论（例如“消化系统疾病”很重要）时，必须提供它这么判断的证据或理由。否则，当结论与临床常识相悖时，医生无法信任。具体建议2：优化界面，主次分明。可以将整体的风险曲线图作为主界面，让医生第一眼就能看到核心信息。具体的特征分析、文字总结等可以作为二级菜单，点击后展开，避免信息过载。具体建议3：细化和溯源笼统的指标。像“消化系统疾病”这种过于笼统的概念，应该能进一步细化。比如，具体是指哪种疾病（溃疡、肿瘤、腹泻等）？这些信息应该可以追溯，否则这个特征就没有意义。 \\
BC-01A & BC-Obstetrics & 主治医师           & 整体界面比较直观，但存在几个问题：1. 首页风险曲线图将三个指标叠在一起，初看时信息量略大。 2. 分析单一指标时操作不太方便，需要多次操作。 3. AI给出的一些建议指标（如红细胞分布宽度）在临床上难以解释或无法干预，不便于向患者提供指导。 & 该工具的优势在于早期预测，适合用于门诊筛查场景。可以在孕中期产检时，输入当时正常的检查值，来预测未来的风险，从而进行早期干预。不太适用于已临近分娩的后期回顾性分析，因为价值不大。 & 如果前期验证模型的准确率高，那么结果是可信的。但对算法处理缺失值的方式（填充数据）有顾虑，担心这种填充会掩盖掉真正重要的风险指标，从而影响最终结果的准确性。 & 信任：当系统基于足够多的数据点，分析出某单一指标的变化趋势，并判断其为重要风险因素时，会觉得可信。 怀疑：当系统筛掉了临床医生认为很重要的指标，没有在最终结论中体现时，会产生怀疑。                                          & 能够从AI的视角反映出风险状态。但更好奇曲线拐点出现的原因，即具体是哪个数据波动导致了风险判断的巨大变化，理解这一点有助于判断结论是否可信。                                                                                                                & 此问题在访谈中未明确问及。                                                                                               & 认为该功能有意义，但对临床使用者来说学习门槛高，日常使用较少。临床医生更关注针对单个病人的直接结论。这个功能可能对模型开发工程师验证模型可信度时更直观有用。                            & 建议内容比较科学，符合临床逻辑。但其建议不一定能抓住当前病人的“主要矛盾”。建议能结合病人当前其他的异常指标（如贫血）和病史进行综合分析，会更好。                                                              & 存在两种矛盾：1. 对关键指标的判断不一致：AI和临床医生认为重要的指标不同，这种情况很难说谁对谁错。 2. 对最终结局的判断不一致：医生会根据病人的合并症、并发症和个人特征来综合判断，而AI是基于所有化验值的统一计算，方法论上的不同导致了冲突。       & 有启发。系统为不同患者识别出的核心风险指标各不相同，其中一些指标（如凝血或肝功里的转氨酶）即便在正常范围内，也可能存在有意义的波动，而这些是临床上通常不会特别关注的。            & 对系统用“填充”方式处理缺失数据表达了较大担忧。认为用填充值来分析，可能会对结果产生很大影响，并建议研究是否可以不填充缺失值，而是通过比如按孕周范围来统计数据的方式进行分析。                                                                                                                                                                               \\
BC-02B & BC-Obstetrics & 副主任医师          &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                       \\
BC-03A & BC-Obstetrics & 主治医师           & 整体理解起来是容易的。但是，右侧的文字性描述部分可能需要花时间细看，建议可以更简洁一些。                                                                              & 会在对一个即将发生的疾病但诊断尚不明确时使用。尤其是在不确定患者是否有早产风险时，可以用来辅助预测。最主要的需求是利用该工具生成动态风险曲线，这是靠人脑难以完成的。        & 效率可以提升。但在准确率方面，AI认为贡献大的指标和我们临床认为意义重大的指标不完全一致，这可能是因为模型纳入的信息有遗漏。                 & 信任：当点击某个指标后，系统呈现的动态变化趋势与认知比较符合时，会产生信任。 怀疑：当AI给出的贡献度高的指标，在临床上缺乏足够的研究证实其意义时，会对其预测的可靠性产生疑惑。                                            & 认为可以帮助构建对患者的整体认知。但目前的系统缺少对主观信息的录入，例如对患者既往早产史的具体情况（如诱因）等细节的记录，而这些对临床判断很重要。                                                                                                             & 用户认为点击查看左下角特征分析列表中的指标趋势，这个操作本身不会影响对整个系统的认知和信任。                                                              & 在日常临床工作中可能用得少。但对于科学研究来说，这个功能的重要性很强。同时用户指出，该图表若无解释则不易看懂。                                                   & 认为目前的文字建议与临床实践结合度不高，甚至有些建议（如“补充磷剂”）在临床上不会使用。建议将这部分替换为更明确的、一目了然的风险数值，例如直接给出在28周、34周、37周前发生早产的具体风险百分比。                                   & 存在矛盾，主要因为临床关注的指标和AI认为贡献大的指标不太一样。处理方式是结合判断，不会完全不信AI，但会把自己认为重要的指标也纳入考虑范围再进行评估。系统的解释功能有助于理解这种差异。                                     & 有启发，尤其是在化验指标方面。例如，系统将甲状腺功能列为高贡献度风险因素，这一点令人诧异，因为临床中甲状腺功能控制极差的孕妇不多。这提示如果数据证实此发现，可能为科研提供新方向。      & 核心建议是提升系统的直观性。具体包括：1. 优化早产定义，区分如28周、34周等不同严重程度的早产节点。 2. 在界面显著位置给出针对这些关键时间节点的明确风险数值。 3. 优化图表的可解释性，例如增加悬浮提示等，让用户能看懂。                                                                                                                                                    \\
BS-01A & BS-Nephrology & 医学生（在读）        &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                       \\
BS-02B & BS-Nephrology & 医学生（在读）        &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                       \\
BS-03A & BS-Nephrology & 住院医师           & 整体的趋势图很直观易懂，但存在一些困惑点：1. 主风险图表的坐标轴（Y轴）文字是竖向的，侧头看比较费力。2. “指标分析2D”图表令人困惑，不理解其含义，属于信息过载。                                      & 可以在ICU查房和普通病房查房的时候使用。                                                                     & 此问题主要由教授回答。                                                                    & 对系统抱着天然的信任感在使用。当系统的结论（如2D曲线的形状）与已有的临床知识相违背时，会感到困惑，但未到不信任的程度。                                                                        & 肯定有帮助。通过观察指标的动态变化趋势（如血红蛋白短时间内下降），可以快速联想到可能的临床情况（如出血），非常有价值。                                                                                                                           & 此问题在访谈中未明确问及。                                                                                               & 认为展示一个“正常范围”或“安全区间”会比目前的3D图更有帮助，因为更符合临床思维。                                                                & 认为建议可以更具体、更具可操作性。例如，如果提示患者低钾，可以进一步建议“是否需要调整饮食结构或近期有无腹泻情况”等。                                                                            & 此问题主要由教授回答。                                                                                                                       & 目前主要还是侧重于观察自己熟悉的指标（如白蛋白、血钾），用以验证AI的判断是否与自己的临床知识一致，而不是发现新的风险因素。但认为系统展示的整体变化趋势帮助很大，非常一目了然。       & 访谈内容已覆盖所有分享要点。                                                                                                                                                                                                                                                        \\
BS-04B & BS-Nephrology & 主任医师           & 系统的主要图表显得特别“乱”，信息过于密集。数据点的大小与其重要性的关联不够直观，且图表中间的核心区域显示得“特别窄”，影响观察。更倾向于之前版本中使用“面积/阴影”来展示风险的方式，认为那样的视觉呈现更清晰。                 & (此问题主要由学生回答)                                                                              & 该工具的核心价值在于“预测风险”，而非“诊断”，因此用“诊断效率”来衡量其作用可能不准确。                                  & 当系统给出的治疗建议与临床经验不符，或其预测的关键指标（如Cystatin C）不符合临床常规认知时，会产生不信任感。                                                                         & 认为用“面积”展示风险变化更清晰明了                                                                                                                                                                    & 此问题在访谈中未明确问及。                                                                                               & 认为当前复杂的2D/3D图表难以理解。建议可以参考常规化验单的模式，给出一个明确的“正常范围”或“安全区间”会更有帮助。                                              & 认为建议功能是必要的，但目前系统给出的建议“不太专业”、“很套话”，需要有文献、指南等证据支持才能采信。                                                                                   & 隐含在对关键特征的讨论中，例如当模型高度关注Cystatin C这类临床上不常用的指标时，就体现了与临床判断的不一致。                                                                       & 此问题主要由学生回答。                                                                                    & 主要对模型本身提出建议和疑问：1. 认为当前模型不直观，信息点过多反而抓不到重点。 2. 强调了模型验证的重要性，认为需要进行外部验证来证明其有效性。 3. 对本数据集特征85个的必要性和效果表示疑问。                                                                                                                                                                 \\
BS-05A & BS-Nephrology & 实习医师/规培医师      &                                                                                                                           &                                                                                           &                                                                                &                                                                                                                                     &                                                                                                                                                                                       &                                                                                                             &                                                                                                           &                                                                                                                                        &                                                                                                                                   &                                                                                                &                                                                                                                                                                                                                                                                      
\end{tabular}
\end{table}

材料二：研究问题（RQs）及核心发现
\subsection{RQ1: How do clinicians perceive the utility and usability of AICare's interactive and interpretable modules when integrated into their diagnostic workflow?}

\paragraph{AICare demonstrated high overall usability.}
The AICare system received a mean System Usability Scale (SUS) score of [INSTRUCT: Insert mean SUS score, e.g., 85.4] (SD = [INSTRUCT: Insert SD, e.g., 7.2]), which is well above the industry average of 68 and indicates a high level of perceived usability. Qualitatively, participants noted that the system's layout was intuitive and aligned with their mental models. A senior nephrologist (BS-04B) commented, ``The flow is logical. It gives me the big picture with the risk curve first, then lets me dig into the details I care about. It feels like a natural extension of how I already think.''
We asked participants to rate the usefulness of each of AICare's core features on a 5-point Likert scale (1=Not useful at all, 5=Extremely useful). All modules received high ratings, indicating their value in the clinical assessment process.
% [INSTRUCT: Create a table or bar chart summarizing the mean usefulness ratings for the four features in the new A, B, C, D order. Then, fill in the text and placeholders below with the specific means and findings from your data.]
The Dynamic Risk Trajectory was rated highest (M = [INSTRUCT: Insert Mean for A, e.g., 4.8], SD = [INSTRUCT: Insert SD for A]), followed by the Interactive Risk Factors list (M = [INSTRUCT: Insert Mean for B, e.g., 4.6], SD = [INSTRUCT: Insert SD for B]), the LLM-driven Recommendation (M = [INSTRUCT: Insert Mean for C, e.g., 4.2], SD = [INSTRUCT: Insert SD for C]), and the Population-level Analysis (M = [INSTRUCT: Insert Mean for D, e.g., 4.0], SD = [INSTRUCT: Insert SD for D]).

The risk trajectory was praised for providing an immediate ``gestalt'' of the patient's condition. An obstetrician (BC-01A) explained, ``Seeing the curve go up over the last few visits is a much faster and more powerful signal than just looking at a table of numbers.'' The interactive risk factors list was seen as the primary tool for verification. ``I don't just take the AI's word for it,'' said a nephrologist from XFPH (XY-06B). ``When it flags creatinine, I want to click on it and see the trend myself. That's how I confirm if the AI is onto something real.''

\subsection{RQ2: What is the impact of AICare on clinicians' diagnostic efficiency, accuracy, and cognitive workload, and how does this impact vary across different clinical contexts and experience levels?}

\paragraph{AICare significantly improved diagnostic efficiency.}
Using AICare led to a substantial reduction in the time required to assess a patient case. The average time per case in the Unassisted condition was [INSTRUCT: Insert mean time in seconds, e.g., 245.7] seconds (SD = [INSTRUCT: Insert SD]), while the average time in the AI-Assisted condition was [INSTRUCT: Insert mean time in seconds, e.g., 158.3] seconds (SD = [INSTRUCT: Insert SD]). A paired-samples t-test showed this reduction to be statistically significant (t([INSTRUCT: df=15]) = [INSTRUCT: t-value], p < [INSTRUCT: p-value, e.g., .001]). Participants attributed this to the system's ability to synthesize information and direct their attention. ``Without the tool, I have to mentally connect all the lab results over time. With AICare, the important patterns are highlighted for me, which is a huge time-saver,'' noted a resident (XY-07A).

\paragraph{Diagnostic accuracy was maintained while confidence increased.}
There was no statistically significant difference in diagnostic accuracy between the two conditions (Unassisted: M = [INSTRUCT: Mean Accuracy]%, AI-Assisted: M = [INSTRUCT: Mean Accuracy]%; p = [INSTRUCT: p-value]). However, participants' self-reported confidence in their assessments significantly increased when using AICare. On a 5-point scale, mean confidence rose from [INSTRUCT: Mean confidence for Unassisted, e.g., 3.5] in the Unassisted condition to [INSTRUCT: Mean confidence for AI-Assisted, e.g., 4.2] in the AI-Assisted condition (t([INSTRUCT: df=15]) = [INSTRUCT: t-value], p < [INSTRUCT: p-value]). This suggests that AICare's value lies not in replacing clinical judgment but in reinforcing it with evidence, leading to more assured decision-making.

\paragraph{AICare substantially reduced cognitive workload.}
The mean NASA-TLX score, a measure of perceived workload, was significantly lower in the AI-Assisted condition (M = [INSTRUCT: Mean TLX for AI, e.g., 35.2], SD = [INSTRUCT: SD]) compared to the Unassisted condition (M = [INSTRUCT: Mean TLX for Unassisted, e.g., 58.6], SD = [INSTRUCT: SD]; t([INSTRUCT: df=15]) = [INSTRUCT: t-value], p < [INSTRUCT: p-value]). Analysis of the TLX subscales revealed the largest reductions in `Mental Demand' and `Effort'. A junior obstetrician (BC-03A) stated, ``Reviewing complex cases can be exhausting. The system shoulders some of that mental burden of synthesis, freeing me up to focus on the clinical implications.''

\paragraph{Impact varied across clinical contexts and experience levels.}
While AICare was beneficial for all participants, we observed nuanced differences. Junior clinicians (students, interns, residents) showed a larger relative improvement in efficiency compared to senior clinicians (attendings and chiefs). They often cited the system as a valuable ``second opinion.'' In contrast, senior clinicians valued it more as an efficient synthesizer of data they would have analyzed anyway. We also noted that clinicians at the regional hospital (XFPH) were particularly enthusiastic, suggesting that such tools could play a significant role in settings with heavier patient loads and potentially fewer sub-specialist resources.

\subsection{RQ3: How do the interactive and interpretable features of AICare influence clinicians' trust in the AI's recommendations?}

\paragraph{AICare fostered a high degree of trust.}
The mean score on the Trust in Automation Scale was [INSTRUCT: Insert mean trust score out of 7, e.g., 6.1] (SD = [INSTRUCT: Insert SD]), indicating a high level of trust in the system. Qualitative feedback revealed that this trust was not blind but was earned through the system's transparency.

\paragraph{Interactivity enabled verification and calibration of trust.}
The most powerful theme to emerge from the interviews was that interactivity is the primary mechanism for building trust. Participants repeatedly described a process of ``checking the AI's work.'' When AICare highlighted a specific risk factor, their immediate instinct was to use the interactive features to verify it. A senior nephrologist (XY-04B) articulated this perfectly: ``Trust is not given, it is built. When the system says albumin is the key factor, I click on albumin. I see its trajectory on the graph. I see how it correlates with the risk curve. Now I don't just see a claim from a black box; I see the evidence. That's when I start to trust it.'' This process of active scrutiny and verification allowed clinicians to calibrate their trust on a case-by-case basis.

\paragraph{Contextual explanations built confidence in the AI's reasoning.}
The population-level analysis view, while used less frequently than the individual patient view, played a key role in justifying trust. It helped clinicians understand if the AI's reasoning was based on common clinical knowledge or if it had identified an unusual pattern. ``For one patient, the AI flagged a slightly elevated potassium level as a major risk factor,'' recounted a chief clinician (BS-04B). ``My initial thought was that it was an overreaction. But when I looked at the population view, I saw that for patients with this specific profile, even small changes in potassium were highly predictive. It taught me something and made me trust that the model was seeing a deeper pattern.''