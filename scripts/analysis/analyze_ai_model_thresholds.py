#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ¨¡åž‹åŸºå‡†æ€§èƒ½è¯¦ç»†åˆ†æžï¼šé˜ˆå€¼ä¼˜åŒ–ç ”ç©¶

è¯¦ç»†åˆ†æžAIæ¨¡åž‹åœ¨ä¸åŒé£Žé™©é˜ˆå€¼ä¸‹çš„æ€§èƒ½è¡¨çŽ°ï¼Œ
åŒ…æ‹¬å½“å‰ä½¿ç”¨çš„50%é˜ˆå€¼å’Œå„æ•°æ®é›†çš„æœ€ä¼˜é˜ˆå€¼ã€‚

ä½œè€…: AICareç ”ç©¶å›¢é˜Ÿ
æ—¥æœŸ: 2025å¹´9æœˆ
"""

import pandas as pd
import numpy as np
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, precision_recall_curve, 
                           roc_curve, auc)
import warnings
warnings.filterwarnings('ignore')

def load_patient_data():
    """åŠ è½½æ‚£è€…æ•°æ®"""
    print("=== AIæ¨¡åž‹åŸºå‡†æ€§èƒ½è¯¦ç»†åˆ†æž ===\n")
    
    patient_data = pd.read_csv('data/patient_last_risk_summary_ordered.csv')
    print(f"âœ“ åŠ è½½æ‚£è€…æ•°æ®: {len(patient_data)}ä¸ªæ¡ˆä¾‹")
    
    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    print("\nðŸ“Š æ•°æ®é›†åˆ†å¸ƒ:")
    for dataset in patient_data['dataset'].unique():
        subset = patient_data[patient_data['dataset'] == dataset]
        n_positive = sum(subset['outcome'])
        n_negative = len(subset) - n_positive
        print(f"  {dataset}: {len(subset)}ä¾‹ (æ­£æ ·æœ¬:{n_positive}, è´Ÿæ ·æœ¬:{n_negative})")
    
    return patient_data

def explain_current_evaluation_method():
    """è§£é‡Šå½“å‰çš„è¯„ä¼°æ–¹æ³•"""
    print("\nðŸ” å½“å‰AIæ¨¡åž‹è¯„ä¼°æ–¹æ³•è¯¦è§£:")
    print("=" * 50)
    
    print("1. **æ•°æ®æ¥æº**: data/patient_last_risk_summary_ordered.csv")
    print("   - åŒ…å«30ä¸ªæ‚£è€…æ¡ˆä¾‹çš„AIé£Žé™©é¢„æµ‹å€¼å’ŒçœŸå®žç»“å±€")
    print("   - åˆ†ä¸º3ä¸ªæ•°æ®é›†ï¼šåŒ—åŒ»å¤šèƒŽ(10ä¾‹)ã€åŒ—åŒ»è‚¾å†…ç§‘(10ä¾‹)ã€å¾åŒ»è‚¾å†…ç§‘(10ä¾‹)")
    
    print("\n2. **å½“å‰ä½¿ç”¨çš„åˆ†ç±»é˜ˆå€¼**: 50%")
    print("   - å¦‚æžœ AIé¢„æµ‹é£Žé™© >= 50%ï¼Œåˆ™é¢„æµ‹ä¸ºæ­£ç±»(é«˜é£Žé™©)")
    print("   - å¦‚æžœ AIé¢„æµ‹é£Žé™© < 50%ï¼Œåˆ™é¢„æµ‹ä¸ºè´Ÿç±»(ä½Žé£Žé™©)")
    
    print("\n3. **è¯„ä¼°æŒ‡æ ‡è®¡ç®—**:")
    print("   - å‡†ç¡®çŽ‡ = (æ­£ç¡®é¢„æµ‹æ•°) / (æ€»é¢„æµ‹æ•°)")
    print("   - ç²¾ç¡®çŽ‡ = (çœŸæ­£ä¾‹) / (çœŸæ­£ä¾‹ + å‡æ­£ä¾‹)")
    print("   - å¬å›žçŽ‡ = (çœŸæ­£ä¾‹) / (çœŸæ­£ä¾‹ + å‡è´Ÿä¾‹)")
    print("   - F1åˆ†æ•° = 2 * (ç²¾ç¡®çŽ‡ * å¬å›žçŽ‡) / (ç²¾ç¡®çŽ‡ + å¬å›žçŽ‡)")
    
    print("\n4. **é—®é¢˜åˆ†æž**:")
    print("   - 50%é˜ˆå€¼æ˜¯ä¸€ä¸ªé€šç”¨é˜ˆå€¼ï¼Œå¯èƒ½ä¸æ˜¯æ¯ä¸ªæ•°æ®é›†çš„æœ€ä¼˜é˜ˆå€¼")
    print("   - ä¸åŒæ•°æ®é›†çš„é£Žé™©åˆ†å¸ƒä¸åŒï¼Œåº”è¯¥ä½¿ç”¨ä¸åŒçš„æœ€ä¼˜é˜ˆå€¼")
    print("   - éœ€è¦é€šè¿‡ROCæ›²çº¿å’ŒPRæ›²çº¿æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼")

def calculate_metrics_for_threshold(y_true, y_scores, threshold):
    """è®¡ç®—æŒ‡å®šé˜ˆå€¼ä¸‹çš„æ‰€æœ‰æŒ‡æ ‡"""
    y_pred = (y_scores >= threshold).astype(int)
    
    metrics = {
        'threshold': threshold,
        'accuracy': accuracy_score(y_true, y_pred),
        'n_samples': len(y_true),
        'n_positive': np.sum(y_true),
        'n_negative': len(y_true) - np.sum(y_true)
    }
    
    # è®¡ç®—æ··æ·†çŸ©é˜µå…ƒç´ 
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    
    metrics.update({
        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn,
        'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,
        'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,
        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,
        'f1_score': 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0
    })
    
    return metrics

def find_optimal_thresholds(patient_data):
    """æ‰¾åˆ°æ¯ä¸ªæ•°æ®é›†çš„æœ€ä¼˜é˜ˆå€¼"""
    print("\nðŸŽ¯ å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼:")
    print("=" * 50)
    
    optimal_results = []
    
    # æµ‹è¯•çš„é˜ˆå€¼èŒƒå›´
    thresholds_to_test = np.arange(0.05, 0.95, 0.05)
    
    for dataset in patient_data['dataset'].unique():
        dataset_data = patient_data[patient_data['dataset'] == dataset]
        y_true = dataset_data['outcome'].values
        y_scores = dataset_data['last_risk_value'].values
        
        print(f"\nðŸ“ˆ åˆ†æžæ•°æ®é›†: {dataset}")
        print(f"   æ ·æœ¬æ•°: {len(dataset_data)}, æ­£æ ·æœ¬: {sum(y_true)}, è´Ÿæ ·æœ¬: {len(y_true) - sum(y_true)}")
        
        # å¦‚æžœåªæœ‰ä¸€ç±»æ ·æœ¬ï¼Œè·³è¿‡
        if len(np.unique(y_true)) == 1:
            print(f"   âš ï¸  åªæœ‰ä¸€ç±»æ ·æœ¬ï¼Œæ— æ³•è®¡ç®—æœ€ä¼˜é˜ˆå€¼")
            continue
        
        # æµ‹è¯•æ‰€æœ‰é˜ˆå€¼
        results = []
        for threshold in thresholds_to_test:
            metrics = calculate_metrics_for_threshold(y_true, y_scores, threshold)
            results.append(metrics)
        
        results_df = pd.DataFrame(results)
        
        # æ‰¾åˆ°å„ç§æŒ‡æ ‡çš„æœ€ä¼˜é˜ˆå€¼
        best_accuracy_idx = results_df['accuracy'].idxmax()
        best_f1_idx = results_df['f1_score'].idxmax()
        
        best_accuracy_threshold = results_df.loc[best_accuracy_idx, 'threshold']
        best_f1_threshold = results_df.loc[best_f1_idx, 'threshold']
        
        # è®¡ç®—å½“å‰50%é˜ˆå€¼çš„æ€§èƒ½
        current_metrics = calculate_metrics_for_threshold(y_true, y_scores, 0.5)
        best_accuracy_metrics = results_df.loc[best_accuracy_idx]
        best_f1_metrics = results_df.loc[best_f1_idx]
        
        print(f"   å½“å‰é˜ˆå€¼(50%): å‡†ç¡®çŽ‡={current_metrics['accuracy']:.4f}, F1={current_metrics['f1_score']:.4f}")
        print(f"   æœ€ä¼˜å‡†ç¡®çŽ‡é˜ˆå€¼({best_accuracy_threshold:.2f}): å‡†ç¡®çŽ‡={best_accuracy_metrics['accuracy']:.4f}")
        print(f"   æœ€ä¼˜F1é˜ˆå€¼({best_f1_threshold:.2f}): F1={best_f1_metrics['f1_score']:.4f}")
        
        # ä¿å­˜ç»“æžœ
        optimal_results.append({
            'dataset': dataset,
            'current_threshold': 0.5,
            'current_accuracy': current_metrics['accuracy'],
            'current_f1': current_metrics['f1_score'],
            'optimal_accuracy_threshold': best_accuracy_threshold,
            'optimal_accuracy': best_accuracy_metrics['accuracy'],
            'optimal_f1_threshold': best_f1_threshold,
            'optimal_f1': best_f1_metrics['f1_score'],
            'accuracy_improvement': best_accuracy_metrics['accuracy'] - current_metrics['accuracy'],
            'f1_improvement': best_f1_metrics['f1_score'] - current_metrics['f1_score'],
            'all_results': results_df
        })
    
    return optimal_results

def analyze_dataset_specific_thresholds(patient_data):
    """åˆ†æžå„æ•°æ®é›†æŽ¨èçš„ç‰¹å®šé˜ˆå€¼"""
    print("\nðŸ“‹ å„æ•°æ®é›†æŽ¨èé˜ˆå€¼åˆ†æž:")
    print("=" * 50)
    
    # ä»Žé£Žé™©é˜ˆå€¼æ–‡ä»¶è¯»å–æŽ¨èé˜ˆå€¼
    recommended_thresholds = {
        'åŒ—åŒ»å¤šèƒŽ': 0.34,
        'åŒ—åŒ»è‚¾å†…ç§‘': 0.522,
        'å¾åŒ»è‚¾å†…ç§‘': 0.503
    }
    
    recommended_results = []
    
    for dataset in patient_data['dataset'].unique():
        dataset_data = patient_data[patient_data['dataset'] == dataset]
        y_true = dataset_data['outcome'].values
        y_scores = dataset_data['last_risk_value'].values
        
        print(f"\nðŸŽ¯ æ•°æ®é›†: {dataset}")
        
        # å½“å‰50%é˜ˆå€¼æ€§èƒ½
        current_metrics = calculate_metrics_for_threshold(y_true, y_scores, 0.5)
        
        # æŽ¨èé˜ˆå€¼æ€§èƒ½
        recommended_threshold = recommended_thresholds.get(dataset, 0.5)
        recommended_metrics = calculate_metrics_for_threshold(y_true, y_scores, recommended_threshold)
        
        print(f"   æŽ¨èé˜ˆå€¼: {recommended_threshold:.3f}")
        print(f"   å½“å‰é˜ˆå€¼(50%): å‡†ç¡®çŽ‡={current_metrics['accuracy']:.4f}, ç²¾ç¡®çŽ‡={current_metrics['precision']:.4f}, å¬å›žçŽ‡={current_metrics['recall']:.4f}")
        print(f"   æŽ¨èé˜ˆå€¼({recommended_threshold:.1%}): å‡†ç¡®çŽ‡={recommended_metrics['accuracy']:.4f}, ç²¾ç¡®çŽ‡={recommended_metrics['precision']:.4f}, å¬å›žçŽ‡={recommended_metrics['recall']:.4f}")
        print(f"   å‡†ç¡®çŽ‡æå‡: {recommended_metrics['accuracy'] - current_metrics['accuracy']:+.4f}")
        
        recommended_results.append({
            'dataset': dataset,
            'recommended_threshold': recommended_threshold,
            'current_accuracy': current_metrics['accuracy'],
            'recommended_accuracy': recommended_metrics['accuracy'],
            'accuracy_improvement': recommended_metrics['accuracy'] - current_metrics['accuracy'],
            'current_metrics': current_metrics,
            'recommended_metrics': recommended_metrics
        })
    
    return recommended_results

def create_threshold_analysis_tables(optimal_results, output_dir):
    """åˆ›å»ºé˜ˆå€¼åˆ†æžè¡¨æ ¼"""
    print("\nðŸ“Š ç”Ÿæˆé˜ˆå€¼åˆ†æžè¡¨æ ¼...")
    
    # åˆ›å»ºè¯¦ç»†çš„é˜ˆå€¼æ€§èƒ½è¡¨
    all_threshold_results = []
    
    for result in optimal_results:
        dataset = result['dataset']
        results_df = result['all_results']
        
        # ä¸ºæ¯ä¸ªé˜ˆå€¼æ·»åŠ æ•°æ®é›†æ ‡è¯†
        for _, row in results_df.iterrows():
            all_threshold_results.append({
                'dataset': dataset,
                **row.to_dict()
            })
    
    # ä¿å­˜æ‰€æœ‰é˜ˆå€¼çš„è¯¦ç»†ç»“æžœ
    threshold_details_df = pd.DataFrame(all_threshold_results)
    threshold_details_df.to_csv(f'{output_dir}/threshold_details_all.csv', index=False, encoding='utf-8-sig')
    
    print("âœ“ é˜ˆå€¼åˆ†æžè¡¨æ ¼å·²ä¿å­˜")

def generate_comprehensive_report(optimal_results, recommended_results, patient_data, output_dir):
    """ç”Ÿæˆç»¼åˆåˆ†æžæŠ¥å‘Š"""
    print("\nðŸ“ ç”Ÿæˆç»¼åˆåˆ†æžæŠ¥å‘Š...")
    
    # åˆ›å»ºè¯¦ç»†çš„ç»“æžœè¡¨æ ¼
    detailed_results = []
    
    # æ€»ä½“æ€§èƒ½å¯¹æ¯”
    for dataset in patient_data['dataset'].unique():
        dataset_data = patient_data[patient_data['dataset'] == dataset]
        y_true = dataset_data['outcome'].values
        y_scores = dataset_data['last_risk_value'].values
        
        # å½“å‰50%é˜ˆå€¼
        current_metrics = calculate_metrics_for_threshold(y_true, y_scores, 0.5)
        
        # æ‰¾åˆ°å¯¹åº”çš„æœ€ä¼˜ç»“æžœ
        optimal_result = next((r for r in optimal_results if r['dataset'] == dataset), None)
        recommended_result = next((r for r in recommended_results if r['dataset'] == dataset), None)
        
        # æ·»åŠ å½“å‰é˜ˆå€¼ç»“æžœ
        detailed_results.append({
            'dataset': dataset,
            'threshold_type': 'å½“å‰ä½¿ç”¨(50%)',
            'threshold': 0.5,
            'accuracy': current_metrics['accuracy'],
            'precision': current_metrics['precision'],
            'recall': current_metrics['recall'],
            'f1_score': current_metrics['f1_score'],
            'specificity': current_metrics['specificity'],
            'tp': current_metrics['tp'],
            'tn': current_metrics['tn'],
            'fp': current_metrics['fp'],
            'fn': current_metrics['fn']
        })
        
        # æ·»åŠ æœ€ä¼˜å‡†ç¡®çŽ‡é˜ˆå€¼ç»“æžœ
        if optimal_result:
            best_acc_metrics = calculate_metrics_for_threshold(
                y_true, y_scores, optimal_result['optimal_accuracy_threshold'])
            detailed_results.append({
                'dataset': dataset,
                'threshold_type': 'æœ€ä¼˜å‡†ç¡®çŽ‡',
                'threshold': optimal_result['optimal_accuracy_threshold'],
                'accuracy': best_acc_metrics['accuracy'],
                'precision': best_acc_metrics['precision'],
                'recall': best_acc_metrics['recall'],
                'f1_score': best_acc_metrics['f1_score'],
                'specificity': best_acc_metrics['specificity'],
                'tp': best_acc_metrics['tp'],
                'tn': best_acc_metrics['tn'],
                'fp': best_acc_metrics['fp'],
                'fn': best_acc_metrics['fn']
            })
        
        # æ·»åŠ æŽ¨èé˜ˆå€¼ç»“æžœ
        if recommended_result:
            rec_metrics = recommended_result['recommended_metrics']
            detailed_results.append({
                'dataset': dataset,
                'threshold_type': 'æ•°æ®é›†æŽ¨è',
                'threshold': recommended_result['recommended_threshold'],
                'accuracy': rec_metrics['accuracy'],
                'precision': rec_metrics['precision'],
                'recall': rec_metrics['recall'],
                'f1_score': rec_metrics['f1_score'],
                'specificity': rec_metrics['specificity'],
                'tp': rec_metrics['tp'],
                'tn': rec_metrics['tn'],
                'fp': rec_metrics['fp'],
                'fn': rec_metrics['fn']
            })
    
    # ä¿å­˜è¯¦ç»†ç»“æžœ
    detailed_df = pd.DataFrame(detailed_results)
    detailed_df.to_csv(f'{output_dir}/ai_model_threshold_analysis.csv', index=False, encoding='utf-8-sig')
    
    # åˆ›å»ºæ€»ç»“è¡¨
    summary_results = []
    for dataset in patient_data['dataset'].unique():
        dataset_results = detailed_df[detailed_df['dataset'] == dataset]
        
        current_acc = dataset_results[dataset_results['threshold_type'] == 'å½“å‰ä½¿ç”¨(50%)']['accuracy'].iloc[0]
        optimal_results_subset = dataset_results[dataset_results['threshold_type'] == 'æœ€ä¼˜å‡†ç¡®çŽ‡']
        recommended_results_subset = dataset_results[dataset_results['threshold_type'] == 'æ•°æ®é›†æŽ¨è']
        
        optimal_acc = optimal_results_subset['accuracy'].iloc[0] if len(optimal_results_subset) > 0 else current_acc
        recommended_acc = recommended_results_subset['accuracy'].iloc[0] if len(recommended_results_subset) > 0 else current_acc
        
        optimal_threshold = optimal_results_subset['threshold'].iloc[0] if len(optimal_results_subset) > 0 else 0.5
        recommended_threshold = recommended_results_subset['threshold'].iloc[0] if len(recommended_results_subset) > 0 else 0.5
        
        summary_results.append({
            'dataset': dataset,
            'current_accuracy_50pct': current_acc,
            'optimal_threshold': optimal_threshold,
            'optimal_accuracy': optimal_acc,
            'optimal_improvement': optimal_acc - current_acc,
            'recommended_threshold': recommended_threshold,
            'recommended_accuracy': recommended_acc,
            'recommended_improvement': recommended_acc - current_acc,
            'best_strategy': 'optimal' if optimal_acc >= recommended_acc else 'recommended'
        })
    
    summary_df = pd.DataFrame(summary_results)
    summary_df.to_csv(f'{output_dir}/ai_model_threshold_summary.csv', index=False, encoding='utf-8-sig')
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    with open(f'{output_dir}/ai_model_threshold_report.txt', 'w', encoding='utf-8') as f:
        f.write("=== AIæ¨¡åž‹é˜ˆå€¼ä¼˜åŒ–åˆ†æžæŠ¥å‘Š ===\n\n")
        
        f.write("## å½“å‰è¯„ä¼°æ–¹æ³•è¯´æ˜Ž\n")
        f.write("å½“å‰è„šæœ¬ä½¿ç”¨å›ºå®šçš„50%é˜ˆå€¼å¯¹æ‰€æœ‰æ•°æ®é›†è¿›è¡ŒäºŒåˆ†ç±»ï¼š\n")
        f.write("- é£Žé™©é¢„æµ‹å€¼ >= 50% â†’ é¢„æµ‹ä¸ºé«˜é£Žé™©(æ­£ç±»)\n")
        f.write("- é£Žé™©é¢„æµ‹å€¼ < 50% â†’ é¢„æµ‹ä¸ºä½Žé£Žé™©(è´Ÿç±»)\n\n")
        
        f.write("## é—®é¢˜åˆ†æž\n")
        f.write("ä½¿ç”¨ç»Ÿä¸€çš„50%é˜ˆå€¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š\n")
        f.write("1. ä¸åŒæ•°æ®é›†çš„é£Žé™©åˆ†å¸ƒå·®å¼‚å¾ˆå¤§\n")
        f.write("2. æ¯ä¸ªæ•°æ®é›†éƒ½æœ‰å…¶ç‰¹å®šçš„æœ€ä¼˜é˜ˆå€¼\n")
        f.write("3. å›ºå®šé˜ˆå€¼æ— æ³•å……åˆ†å‘æŒ¥AIæ¨¡åž‹çš„é¢„æµ‹èƒ½åŠ›\n\n")
        
        f.write("## ä¼˜åŒ–å»ºè®®\n")
        for idx, row in summary_df.iterrows():
            f.write(f"\n### {row['dataset']}\n")
            f.write(f"- å½“å‰å‡†ç¡®çŽ‡(50%é˜ˆå€¼): {row['current_accuracy_50pct']:.4f}\n")
            f.write(f"- æœ€ä¼˜é˜ˆå€¼: {row['optimal_threshold']:.3f}, å‡†ç¡®çŽ‡: {row['optimal_accuracy']:.4f} (æå‡: {row['optimal_improvement']:+.4f})\n")
            f.write(f"- æŽ¨èé˜ˆå€¼: {row['recommended_threshold']:.3f}, å‡†ç¡®çŽ‡: {row['recommended_accuracy']:.4f} (æå‡: {row['recommended_improvement']:+.4f})\n")
            f.write(f"- å»ºè®®ä½¿ç”¨: {'æœ€ä¼˜é˜ˆå€¼' if row['best_strategy'] == 'optimal' else 'æŽ¨èé˜ˆå€¼'}\n")
        
        # æ€»ä½“æ”¹è¿›æ½œåŠ›
        total_current = summary_df['current_accuracy_50pct'].mean()
        total_optimal = summary_df['optimal_accuracy'].mean()
        total_recommended = summary_df['recommended_accuracy'].mean()
        
        f.write(f"\n## æ€»ä½“æ”¹è¿›æ½œåŠ›\n")
        f.write(f"- å½“å‰å¹³å‡å‡†ç¡®çŽ‡: {total_current:.4f}\n")
        f.write(f"- æœ€ä¼˜é˜ˆå€¼å¹³å‡å‡†ç¡®çŽ‡: {total_optimal:.4f} (æå‡: {total_optimal - total_current:+.4f})\n")
        f.write(f"- æŽ¨èé˜ˆå€¼å¹³å‡å‡†ç¡®çŽ‡: {total_recommended:.4f} (æå‡: {total_recommended - total_current:+.4f})\n")
    
    print("âœ“ ç»¼åˆåˆ†æžæŠ¥å‘Šå·²ç”Ÿæˆ")
    
    return detailed_df, summary_df

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'results/rq2_performance_analysis'
    
    # åŠ è½½æ•°æ®
    patient_data = load_patient_data()
    
    # è§£é‡Šå½“å‰è¯„ä¼°æ–¹æ³•
    explain_current_evaluation_method()
    
    # å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼
    optimal_results = find_optimal_thresholds(patient_data)
    
    # åˆ†æžæŽ¨èé˜ˆå€¼
    recommended_results = analyze_dataset_specific_thresholds(patient_data)
    
    # ç”Ÿæˆè¯¦ç»†è¡¨æ ¼
    if optimal_results:
        create_threshold_analysis_tables(optimal_results, output_dir)
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    detailed_df, summary_df = generate_comprehensive_report(
        optimal_results, recommended_results, patient_data, output_dir)
    
    # æ˜¾ç¤ºå…³é”®å‘çŽ°
    print("\nðŸŽ¯ å…³é”®å‘çŽ°:")
    print("=" * 50)
    
    for idx, row in summary_df.iterrows():
        dataset = row['dataset']
        current_acc = row['current_accuracy_50pct']
        optimal_acc = row['optimal_accuracy']
        optimal_threshold = row['optimal_threshold']
        improvement = row['optimal_improvement']
        
        print(f"\nðŸ“Š {dataset}:")
        print(f"   å½“å‰å‡†ç¡®çŽ‡(50%): {current_acc:.1%}")
        print(f"   æœ€ä¼˜å‡†ç¡®çŽ‡({optimal_threshold:.1%}): {optimal_acc:.1%}")
        print(f"   æ½œåœ¨æå‡: {improvement:+.1%}")
    
    total_improvement = summary_df['optimal_improvement'].mean()
    print(f"\nðŸš€ æ€»ä½“æ½œåœ¨æå‡: {total_improvement:+.1%}")
    
    print(f"\nðŸ“ æ‰€æœ‰åˆ†æžæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}/")
    print("   - ai_model_threshold_analysis.csv (è¯¦ç»†ç»“æžœ)")
    print("   - ai_model_threshold_summary.csv (æ±‡æ€»ç»“æžœ)")
    print("   - ai_model_threshold_report.txt (åˆ†æžæŠ¥å‘Š)")
    print("   - threshold_details_all.csv (æ‰€æœ‰é˜ˆå€¼è¯¦ç»†æ€§èƒ½)")

if __name__ == "__main__":
    main()
