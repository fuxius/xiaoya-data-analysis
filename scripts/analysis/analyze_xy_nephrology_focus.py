#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XY-Nephrologyä¸“é¡¹åˆ†æï¼šé«˜è´¨é‡æ•°æ®é›†æ·±åº¦åˆ†æ

æœ¬è„šæœ¬ä¸“é—¨åˆ†æå¾å·ç¬¬ä¸€äººæ°‘åŒ»é™¢è‚¾å†…ç§‘çš„æ•°æ®ï¼Œè¯¥æ•°æ®é›†å…·æœ‰æœ€é«˜çš„è´¨é‡ï¼š
1. æ ·æœ¬é‡å……è¶³ï¼ˆ8ä½åŒ»ç”Ÿï¼‰
2. å¹´èµ„åˆ†å¸ƒå‡è¡¡ï¼ˆé«˜å¹´èµ„5ä½ï¼Œä½å¹´èµ„3ä½ï¼‰
3. AIæ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼ˆå‡†ç¡®ç‡80%ï¼‰
4. æ•°æ®å®Œæ•´æ€§å¥½ï¼Œå¯è®¡ç®—å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡

ä½œè€…: AICareç ”ç©¶å›¢é˜Ÿ
æ—¥æœŸ: 2025å¹´9æœˆ
"""

import pandas as pd
import numpy as np
import json
import re
from scipy import stats
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, 
                           precision_recall_curve, auc)
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥rm-ANOVAåˆ†ææ¨¡å—
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'utils'))
from rm_anova_analysis import perform_rm_anova_analysis, print_rm_anova_summary

def load_data():
    """åŠ è½½æ‰€æœ‰å¿…è¦æ•°æ®"""
    print("=== XY-Nephrologyä¸“é¡¹åˆ†æ ===")
    print("å¾å·ç¬¬ä¸€äººæ°‘åŒ»é™¢è‚¾å†…ç§‘é«˜è´¨é‡æ•°æ®é›†æ·±åº¦åˆ†æ\n")
    
    # åŠ è½½åˆå¹¶æ•°æ®é›†
    try:
        df = pd.read_excel('results/datasets/merged_dataset_simple.xlsx')
        print(f"âœ“ æˆåŠŸåŠ è½½åˆå¹¶æ•°æ®é›†: {df.shape}")
    except:
        df = pd.read_excel('results/datasets/merged_dataset_simple.xlsx')
        print(f"âœ“ æˆåŠŸåŠ è½½åˆå¹¶æ•°æ®é›†: {df.shape}")
    
    # åŠ è½½å¹´èµ„åˆ†ç±»
    with open('results/participants/seniority_classification.json', 'r', encoding='utf-8') as f:
        seniority_data = json.load(f)
    print("âœ“ æˆåŠŸåŠ è½½å¹´èµ„åˆ†ç±»æ•°æ®")
    
    # åŠ è½½æ‚£è€…ç»“æœæ•°æ®
    patient_data = pd.read_csv('data/patient_last_risk_summary_ordered.csv')
    print(f"âœ“ æˆåŠŸåŠ è½½æ‚£è€…ç»“æœæ•°æ®: {patient_data.shape}")
    
    return df, seniority_data, patient_data

def explain_data_quality_rationale():
    """è§£é‡Šæ•°æ®è´¨é‡é€‰æ‹©çš„ç†ç”±"""
    print("\nğŸ“Š æ•°æ®è´¨é‡è¯„ä¼°å’Œé€‰æ‹©ç†ç”±:")
    print("=" * 60)
    
    print("ğŸ¯ **é€‰æ‹©XY-Nephrologyä½œä¸ºä¸»è¦åˆ†æå¯¹è±¡çš„åŸå› :**")
    print("   1. **æ ·æœ¬é‡å……è¶³**: 8ä½åŒ»ç”Ÿå‚ä¸ï¼Œæ ·æœ¬é‡æœ€å¤§")
    print("   2. **å¹´èµ„åˆ†å¸ƒå‡è¡¡**: é«˜å¹´èµ„5ä½ï¼Œä½å¹´èµ„3ä½ï¼Œä¾¿äºå¯¹æ¯”åˆ†æ")
    print("   3. **AIæ¨¡å‹è¡¨ç°æœ€ä½³**: åœ¨å¾åŒ»è‚¾å†…ç§‘æ•°æ®é›†ä¸Šå‡†ç¡®ç‡è¾¾80%")
    print("   4. **æ•°æ®å®Œæ•´æ€§å¥½**: æ­£è´Ÿæ ·æœ¬åˆ†å¸ƒåˆç†ï¼Œå¯è®¡ç®—å®Œæ•´æŒ‡æ ‡")
    print("   5. **ä¸´åºŠæ„ä¹‰é‡å¤§**: ESRDæ‚£è€…æ­»äº¡é£é™©é¢„æµ‹ï¼Œä¸´åºŠä»·å€¼é«˜")
    
    print("\nâš ï¸  **å…¶ä»–æ•°æ®é›†å­˜åœ¨çš„é—®é¢˜:**")
    
    print("\n   ğŸ”¸ **BC-Obstetrics (åŒ—åŒ»äº§ç§‘)çš„é—®é¢˜:**")
    print("      - æ ·æœ¬é‡è¿‡å°ï¼šä»…3ä½åŒ»ç”Ÿ")
    print("      - ç»Ÿè®¡åŠŸæ•ˆä¸è¶³ï¼šéš¾ä»¥å¾—å‡ºå¯é ç»“è®º")
    print("      - åˆ†ç»„åˆ†æå—é™ï¼šæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„äºšç»„åˆ†æ")
    print("      - ä»£è¡¨æ€§ä¸è¶³ï¼šæ ·æœ¬é‡å¤ªå°ï¼Œéš¾ä»¥æ¨å¹¿")
    
    print("\n   ğŸ”¸ **BS-Nephrology (åŒ—åŒ»è‚¾å†…ç§‘)çš„é—®é¢˜:**")
    print("      - å¹´èµ„åˆ†å¸ƒæä¸å‡è¡¡ï¼š5ä½åŒ»ç”Ÿä¸­4ä½ä¸ºä½å¹´èµ„")
    print("      - ä½å¹´èµ„åŒ»ç”Ÿå æ¯”80%ï¼Œç¼ºä¹é«˜å¹´èµ„åŒ»ç”Ÿçš„å……åˆ†ä»£è¡¨")
    print("      - AIè¾…åŠ©æ•ˆæœå·®ï¼šè¯¥ç»„AIè¾…åŠ©åè€Œé™ä½å‡†ç¡®ç‡28%")
    print("      - æ•°æ®è´¨é‡é—®é¢˜ï¼šå¯èƒ½å­˜åœ¨ç»éªŒä¸è¶³å¯¼è‡´çš„è¯„ä¼°åå·®")
    
    print("\nâœ… **å› æ­¤ï¼ŒXY-Nephrologyæ•°æ®é›†æ˜¯æœ€é€‚åˆæ·±åº¦åˆ†æçš„é«˜è´¨é‡æ•°æ®**")

def analyze_xy_participants():
    """åˆ†æXY-Nephrologyå‚ä¸è€…åŸºæœ¬ä¿¡æ¯"""
    print("\nğŸ‘¥ XY-Nephrologyå‚ä¸è€…è¯¦ç»†åˆ†æ:")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    df, seniority_data, _ = load_data()
    
    # ç­›é€‰XY-Nephrologyå‚ä¸è€…
    xy_participants = df[df['ç§‘å®¤'] == 'XY-Nephrology'].copy()
    
    # æ·»åŠ å¹´èµ„ä¿¡æ¯
    xy_participants['å¹´èµ„åˆ†ç±»'] = xy_participants['ID'].map(
        lambda x: seniority_data['participant_classification'].get(x, {}).get('seniority_level', 'æœªçŸ¥'))
    
    print(f"å‚ä¸è€…æ€»æ•°: {len(xy_participants)}")
    print(f"å¹´èµ„åˆ†å¸ƒ: {xy_participants['å¹´èµ„åˆ†ç±»'].value_counts().to_dict()}")
    
    # è¯¦ç»†å‚ä¸è€…ä¿¡æ¯
    print("\nè¯¦ç»†å‚ä¸è€…ä¿¡æ¯:")
    for idx, row in xy_participants.iterrows():
        participant_id = row['ID']
        seniority = row['å¹´èµ„åˆ†ç±»']
        ai_first = 'å…ˆç”¨AI' if row['æ˜¯å¦å…ˆä½¿ç”¨AIåˆ†æç³»ç»Ÿ'] == 'æ˜¯' else 'åç”¨AI'
        print(f"  {participant_id}: {seniority} ({ai_first})")
    
    return xy_participants

def calculate_ai_model_performance_xy():
    """è®¡ç®—AIæ¨¡å‹åœ¨å¾åŒ»è‚¾å†…ç§‘æ•°æ®é›†ä¸Šçš„è¯¦ç»†æ€§èƒ½"""
    print("\nğŸ¤– AIæ¨¡å‹åœ¨å¾åŒ»è‚¾å†…ç§‘çš„åŸºå‡†æ€§èƒ½:")
    print("=" * 50)
    
    # åŠ è½½æ‚£è€…æ•°æ®
    patient_data = pd.read_csv('data/patient_last_risk_summary_ordered.csv')
    xy_data = patient_data[patient_data['dataset'] == 'å¾åŒ»è‚¾å†…ç§‘']
    
    y_true = xy_data['outcome'].values
    y_scores = xy_data['last_risk_value'].values
    
    print(f"æ•°æ®é›†è§„æ¨¡: {len(xy_data)}ä¸ªæ¡ˆä¾‹")
    print(f"æ­£æ ·æœ¬(æ­»äº¡): {sum(y_true)}ä¾‹")
    print(f"è´Ÿæ ·æœ¬(å­˜æ´»): {len(y_true) - sum(y_true)}ä¾‹")
    print(f"æ­£æ ·æœ¬æ¯”ä¾‹: {sum(y_true)/len(y_true):.1%}")
    
    # æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼
    thresholds = sorted(set(y_scores))
    best_acc = 0
    best_threshold = 50.0
    
    print(f"\né˜ˆå€¼ä¼˜åŒ–åˆ†æ:")
    for threshold in thresholds:
        y_pred = (y_scores >= threshold).astype(int)
        accuracy = accuracy_score(y_true, y_pred)
        if accuracy > best_acc:
            best_acc = accuracy
            best_threshold = threshold
        print(f"  é˜ˆå€¼{threshold:6.2f}: å‡†ç¡®ç‡={accuracy:.3f}")
    
    # ä½¿ç”¨æœ€ä¼˜é˜ˆå€¼è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    y_pred_optimal = (y_scores >= best_threshold).astype(int)
    
    metrics = {
        'threshold': best_threshold,
        'accuracy': accuracy_score(y_true, y_pred_optimal),
        'precision': precision_score(y_true, y_pred_optimal, zero_division=0),
        'recall': recall_score(y_true, y_pred_optimal, zero_division=0),
        'f1_score': f1_score(y_true, y_pred_optimal, zero_division=0),
        'auroc': roc_auc_score(y_true, y_scores),
        'n_samples': len(y_true),
        'n_positive': sum(y_true),
        'n_negative': len(y_true) - sum(y_true)
    }
    
    # è®¡ç®—AUPRC
    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_scores)
    metrics['auprc'] = auc(recall_curve, precision_curve)
    
    # è®¡ç®—ç‰¹å¼‚æ€§
    tn = np.sum((y_true == 0) & (y_pred_optimal == 0))
    fp = np.sum((y_true == 0) & (y_pred_optimal == 1))
    metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    print(f"\nğŸ¯ AIæ¨¡å‹æœ€ä¼˜æ€§èƒ½ (é˜ˆå€¼={best_threshold:.1f}):")
    print(f"   å‡†ç¡®ç‡: {metrics['accuracy']:.1%}")
    print(f"   ç²¾ç¡®ç‡: {metrics['precision']:.1%}")
    print(f"   å¬å›ç‡: {metrics['recall']:.1%}")
    print(f"   ç‰¹å¼‚æ€§: {metrics['specificity']:.1%}")
    print(f"   F1åˆ†æ•°: {metrics['f1_score']:.3f}")
    print(f"   AUROC: {metrics['auroc']:.3f}")
    print(f"   AUPRC: {metrics['auprc']:.3f}")
    
    return metrics

def extract_xy_clinician_data():
    """æå–XY-NephrologyåŒ»ç”Ÿçš„é£é™©è¯„ä¼°æ•°æ®"""
    print("\nğŸ“‹ æå–XY-NephrologyåŒ»ç”Ÿè¯„ä¼°æ•°æ®:")
    print("=" * 50)
    
    df, seniority_data, patient_data = load_data()
    
    # ç­›é€‰XYå‚ä¸è€…
    xy_participants = df[df['ç§‘å®¤'] == 'XY-Nephrology'].copy()
    xy_participants['å¹´èµ„åˆ†ç±»'] = xy_participants['ID'].map(
        lambda x: seniority_data['participant_classification'].get(x, {}).get('seniority_level', 'æœªçŸ¥'))
    
    # æ‰¾åˆ°é£é™©è¯„ä¼°ç›¸å…³çš„åˆ—
    risk_assessment_cols = []
    for col in df.columns:
        if 'æ‚¨å¦‚ä½•è¯„ä¼°æ‚£è€…' in col and 'æ­»äº¡é£é™©' in col:
            risk_assessment_cols.append(col)
    
    print(f"æ‰¾åˆ°é£é™©è¯„ä¼°åˆ—æ•°: {len(risk_assessment_cols)}")
    
    # åˆ›å»ºæ‚£è€…ç¼–å·åˆ°æ•°æ®é›†çš„æ˜ å°„
    patient_mapping = {}
    xy_patient_data = patient_data[patient_data['dataset'] == 'å¾åŒ»è‚¾å†…ç§‘']
    for idx, row in xy_patient_data.iterrows():
        key = f"å¾åŒ»è‚¾å†…ç§‘_{row['patient_number']}"
        patient_mapping[key] = {
            'dataset': row['dataset'],
            'patient_number': row['patient_number'],
            'outcome': row['outcome']
        }
    
    # æå–æ¯ä¸ªXYåŒ»ç”Ÿå¯¹æ¯ä¸ªæ‚£è€…çš„è¯„ä¼°
    clinician_assessments = []
    
    for idx, row in xy_participants.iterrows():
        participant_id = row['ID']
        
        # æå–è¯¥å‚ä¸è€…çš„æ‰€æœ‰é£é™©è¯„ä¼°
        for col in risk_assessment_cols:
            if pd.notna(row[col]) and row[col] != '(è·³è¿‡)':
                # ä»åˆ—åä¸­æå–æ‚£è€…ç¼–å·
                patient_match = re.search(r'æ‚£è€…(\d+)', col)
                if patient_match:
                    patient_num = int(patient_match.group(1))
                    
                    # æŸ¥æ‰¾å¯¹åº”çš„çœŸå®ç»“æœ
                    patient_key = f"å¾åŒ»è‚¾å†…ç§‘_{patient_num}"
                    if patient_key in patient_mapping:
                        risk_score = convert_risk_assessment_to_score(row[col])
                        
                        if not pd.isna(risk_score):
                            clinician_assessments.append({
                                'participant_id': participant_id,
                                'patient_number': patient_num,
                                'risk_text': row[col],
                                'risk_score': risk_score,
                                'true_outcome': patient_mapping[patient_key]['outcome'],
                                'case_order': patient_num
                            })
    
    clinician_df = pd.DataFrame(clinician_assessments)
    print(f"æå–åˆ°XYåŒ»ç”Ÿè¯„ä¼°è®°å½•: {len(clinician_df)}æ¡")
    
    return clinician_df, xy_participants

def convert_risk_assessment_to_score(risk_text):
    """å°†é£é™©è¯„ä¼°æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°"""
    if pd.isna(risk_text) or risk_text == '(è·³è¿‡)':
        return np.nan
    
    risk_mapping = {
        '0-25%': 12.5,
        '25-50%': 37.5,
        '50-75%': 62.5,
        '75-100%': 87.5
    }
    
    for key, value in risk_mapping.items():
        if key in str(risk_text):
            return value
    
    return np.nan

def assign_ai_conditions_xy(xy_participants, clinician_df):
    """ä¸ºXYåŒ»ç”Ÿåˆ†é…AIè¾…åŠ©æ¡ä»¶"""
    print("\nğŸ”„ åˆ†é…AIè¾…åŠ©æ¡ä»¶:")
    print("=" * 30)
    
    condition_data = []
    
    for idx, row in clinician_df.iterrows():
        participant_id = row['participant_id']
        case_order = row['case_order']
        
        # è·å–è¯¥å‚ä¸è€…çš„AIä½¿ç”¨é¡ºåº
        participant_info = xy_participants[xy_participants['ID'] == participant_id].iloc[0]
        ai_first = participant_info['æ˜¯å¦å…ˆä½¿ç”¨AIåˆ†æç³»ç»Ÿ'] == 'æ˜¯'
        
        # ç¡®å®šæ¡ä»¶
        if ai_first:
            condition = 'AIè¾…åŠ©' if case_order <= 5 else 'æ— è¾…åŠ©'
        else:
            condition = 'æ— è¾…åŠ©' if case_order <= 5 else 'AIè¾…åŠ©'
        
        condition_data.append({
            **row.to_dict(),
            'ai_first': ai_first,
            'condition': condition,
            'seniority': participant_info['å¹´èµ„åˆ†ç±»']
        })
    
    condition_df = pd.DataFrame(condition_data)
    
    print("æ¡ä»¶åˆ†é…ç»Ÿè®¡:")
    print(condition_df['condition'].value_counts())
    print("\nå¹´èµ„Ã—æ¡ä»¶äº¤å‰è¡¨:")
    print(pd.crosstab(condition_df['seniority'], condition_df['condition']))
    
    return condition_df

def calculate_xy_individual_performance(condition_df):
    """è®¡ç®—XYæ¯ä¸ªåŒ»ç”Ÿçš„ä¸ªä½“æ€§èƒ½"""
    print("\nğŸ‘¨â€âš•ï¸ XYåŒ»ç”Ÿä¸ªä½“æ€§èƒ½åˆ†æ:")
    print("=" * 40)
    
    individual_performance = []
    
    for participant_id in condition_df['participant_id'].unique():
        participant_data = condition_df[condition_df['participant_id'] == participant_id]
        seniority = participant_data.iloc[0]['seniority']
        
        print(f"\nåˆ†æåŒ»ç”Ÿ: {participant_id} ({seniority})")
        
        # ä¸ºæ¯ç§æ¡ä»¶è®¡ç®—æ€§èƒ½
        for condition in ['AIè¾…åŠ©', 'æ— è¾…åŠ©']:
            condition_assessments = participant_data[participant_data['condition'] == condition]
            
            if len(condition_assessments) >= 3:
                y_true = condition_assessments['true_outcome'].values
                y_scores = condition_assessments['risk_score'].values
                y_pred = (y_scores >= 50).astype(int)
                
                # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
                accuracy = accuracy_score(y_true, y_pred)
                
                # è®¡ç®—å…¶ä»–æŒ‡æ ‡
                precision_val = np.nan
                recall_val = np.nan
                f1_score_val = np.nan
                specificity_val = np.nan
                auroc_val = np.nan
                auprc_val = np.nan
                
                # ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1 (éœ€è¦æ­£æ ·æœ¬)
                if np.sum(y_true) > 0:
                    precision_val = precision_score(y_true, y_pred, zero_division=0)
                    recall_val = recall_score(y_true, y_pred, zero_division=0)
                    f1_score_val = f1_score(y_true, y_pred, zero_division=0)
                
                # ç‰¹å¼‚æ€§ (éœ€è¦è´Ÿæ ·æœ¬)
                if np.sum(1 - y_true) > 0:
                    tn = np.sum((y_true == 0) & (y_pred == 0))
                    fp = np.sum((y_true == 0) & (y_pred == 1))
                    specificity_val = tn / (tn + fp) if (tn + fp) > 0 else 0
                
                # AUROC, AUPRC (éœ€è¦æ­£è´Ÿæ ·æœ¬æ··åˆ)
                if len(np.unique(y_true)) > 1:
                    try:
                        auroc_val = roc_auc_score(y_true, y_scores)
                        precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_scores)
                        auprc_val = auc(recall_curve, precision_curve)
                    except Exception:
                        pass
                
                print(f"  {condition}: å‡†ç¡®ç‡={accuracy:.1%}, æ¡ˆä¾‹æ•°={len(condition_assessments)}")
                
                individual_performance.append({
                    'participant_id': participant_id,
                    'seniority': seniority,
                    'condition': condition,
                    'n_cases': len(condition_assessments),
                    'n_positive': np.sum(y_true),
                    'n_negative': len(y_true) - np.sum(y_true),
                    'accuracy': accuracy,
                    'precision': precision_val,
                    'recall': recall_val,
                    'f1_score': f1_score_val,
                    'specificity': specificity_val,
                    'auroc': auroc_val,
                    'auprc': auprc_val
                })
    
    return pd.DataFrame(individual_performance)

def perform_xy_statistical_analysis(individual_performance_df):
    """æ‰§è¡ŒXYæ•°æ®çš„ç»Ÿè®¡åˆ†æ"""
    print("\nğŸ“ˆ XY-Nephrologyç»Ÿè®¡åˆ†æ:")
    print("=" * 40)
    
    # æ€»ä½“åˆ†æ
    print("ğŸ¯ æ€»ä½“æ•ˆæœåˆ†æ:")
    
    # è·å–é…å¯¹æ•°æ®
    paired_data = []
    for pid in individual_performance_df['participant_id'].unique():
        pid_data = individual_performance_df[individual_performance_df['participant_id'] == pid]
        ai_data = pid_data[pid_data['condition'] == 'AIè¾…åŠ©']
        no_ai_data = pid_data[pid_data['condition'] == 'æ— è¾…åŠ©']
        
        if len(ai_data) > 0 and len(no_ai_data) > 0:
            paired_data.append({
                'participant_id': pid,
                'seniority': ai_data.iloc[0]['seniority'],
                'ai_accuracy': ai_data.iloc[0]['accuracy'],
                'no_ai_accuracy': no_ai_data.iloc[0]['accuracy'],
                'difference': ai_data.iloc[0]['accuracy'] - no_ai_data.iloc[0]['accuracy']
            })
    
    paired_df = pd.DataFrame(paired_data)
    
    # åˆ›å»ºç»Ÿè®¡ç»“æœå­˜å‚¨
    statistical_results = []
    
    # æ€»ä½“ç»Ÿè®¡æ£€éªŒ - ä½¿ç”¨rm-ANOVA
    if len(paired_data) > 1:
        ai_accuracies = [p['ai_accuracy'] for p in paired_data]
        no_ai_accuracies = [p['no_ai_accuracy'] for p in paired_data]
        
        print(f"   é…å¯¹æ ·æœ¬æ•°: {len(paired_data)}")
        print(f"   AIè¾…åŠ©å‡†ç¡®ç‡: {np.mean(ai_accuracies):.1%} Â± {np.std(ai_accuracies, ddof=1):.1%}")
        print(f"   æ— è¾…åŠ©å‡†ç¡®ç‡: {np.mean(no_ai_accuracies):.1%} Â± {np.std(no_ai_accuracies, ddof=1):.1%}")
        print(f"   å¹³å‡æå‡: {np.mean([p['difference'] for p in paired_data]):+.1%}")
        
        # å‡†å¤‡é•¿æ ¼å¼æ•°æ®è¿›è¡Œrm-ANOVA
        long_data = []
        for p in paired_data:
            long_data.extend([
                {'participant_id': p['participant_id'], 'condition': 'AIè¾…åŠ©', 'accuracy': p['ai_accuracy'], 'seniority': p['seniority']},
                {'participant_id': p['participant_id'], 'condition': 'æ— è¾…åŠ©', 'accuracy': p['no_ai_accuracy'], 'seniority': p['seniority']}
            ])
        
        long_df = pd.DataFrame(long_data)
        
        # æ‰§è¡Œrm-ANOVA
        print(f"\n   æ‰§è¡Œrm-ANOVAåˆ†æ:")
        rm_results = perform_rm_anova_analysis(
            long_df,
            participant_col='participant_id',
            condition_col='condition',
            dv_col='accuracy'
        )
        
        if rm_results:
            print_rm_anova_summary(rm_results, "XY-Nephrologyæ€»ä½“åˆ†æ")
            
            # æå–ç»Ÿè®¡é‡
            main_effect = rm_results.get('main_effect', pd.DataFrame())
            effect_size = rm_results.get('effect_size_pes', pd.DataFrame())
            
            if len(main_effect) > 0 and 'Pr(>F)' in main_effect.columns:
                p_value = main_effect['Pr(>F)'].iloc[0]
                f_value = main_effect['F'].iloc[0] if 'F' in main_effect.columns else np.nan
                pes_value = effect_size['pes'].iloc[0] if len(effect_size) > 0 and 'pes' in effect_size.columns else np.nan
                
                print(f"   Fç»Ÿè®¡é‡: {f_value:.3f}")
                print(f"   på€¼: {p_value:.4f}")
                print(f"   ç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¯' if p_value < 0.05 else 'å¦'}")
                
                # ä¿å­˜æ€»ä½“ç»Ÿè®¡ç»“æœ
                statistical_results.append({
                    'analysis_type': 'æ€»ä½“åˆ†æ',
                    'group': 'å…¨éƒ¨å‚ä¸è€…',
                    'n_participants': len(paired_data),
                    'ai_mean_accuracy': np.mean(ai_accuracies),
                    'ai_std_accuracy': np.std(ai_accuracies, ddof=1),
                    'no_ai_mean_accuracy': np.mean(no_ai_accuracies),
                    'no_ai_std_accuracy': np.std(no_ai_accuracies, ddof=1),
                    'mean_difference': np.mean([p['difference'] for p in paired_data]),
                    'f_value': f_value,
                    'p_value': p_value,
                    'partial_eta_squared': pes_value,
                    'statistical_method': 'RM-ANOVA',
                    'significance': 'Yes' if p_value < 0.05 else 'No'
                })
        else:
            print("   rm-ANOVAåˆ†æå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡æ£€éªŒ")
            # ä¿å­˜å¤±è´¥è®°å½•
            statistical_results.append({
                'analysis_type': 'æ€»ä½“åˆ†æ',
                'group': 'å…¨éƒ¨å‚ä¸è€…',
                'n_participants': len(paired_data),
                'ai_mean_accuracy': np.mean(ai_accuracies),
                'ai_std_accuracy': np.std(ai_accuracies, ddof=1),
                'no_ai_mean_accuracy': np.mean(no_ai_accuracies),
                'no_ai_std_accuracy': np.std(no_ai_accuracies, ddof=1),
                'mean_difference': np.mean([p['difference'] for p in paired_data]),
                'f_value': np.nan,
                'p_value': np.nan,
                'partial_eta_squared': np.nan,
                'statistical_method': 'RM-ANOVA',
                'significance': 'Failed'
            })
    
    # å¹´èµ„åˆ†ç»„åˆ†æ
    print(f"\nğŸ“ å¹´èµ„åˆ†ç»„åˆ†æ:")
    
    for seniority in ['é«˜å¹´èµ„', 'ä½å¹´èµ„']:
        seniority_data = paired_df[paired_df['seniority'] == seniority]
        if len(seniority_data) > 1:
            ai_acc = seniority_data['ai_accuracy']
            no_ai_acc = seniority_data['no_ai_accuracy']
            
            print(f"   {seniority} (n={len(seniority_data)}):")
            print(f"     AIè¾…åŠ©: {ai_acc.mean():.1%} Â± {ai_acc.std(ddof=1):.1%}")
            print(f"     æ— è¾…åŠ©: {no_ai_acc.mean():.1%} Â± {no_ai_acc.std(ddof=1):.1%}")
            print(f"     æå‡: {seniority_data['difference'].mean():+.1%}")
            
            # å‡†å¤‡å¹´èµ„åˆ†ç»„çš„é•¿æ ¼å¼æ•°æ®è¿›è¡Œrm-ANOVA
            seniority_long_data = []
            for idx, row in seniority_data.iterrows():
                seniority_long_data.extend([
                    {'participant_id': row['participant_id'], 'condition': 'AIè¾…åŠ©', 'accuracy': row['ai_accuracy']},
                    {'participant_id': row['participant_id'], 'condition': 'æ— è¾…åŠ©', 'accuracy': row['no_ai_accuracy']}
                ])
            
            seniority_long_df = pd.DataFrame(seniority_long_data)
            
            # æ‰§è¡Œå¹´èµ„åˆ†ç»„rm-ANOVA
            seniority_rm_results = perform_rm_anova_analysis(
                seniority_long_df,
                participant_col='participant_id',
                condition_col='condition',
                dv_col='accuracy'
            )
            
            if seniority_rm_results:
                main_effect = seniority_rm_results.get('main_effect', pd.DataFrame())
                effect_size = seniority_rm_results.get('effect_size_pes', pd.DataFrame())
                
                if len(main_effect) > 0 and 'Pr(>F)' in main_effect.columns:
                    p_value_sen = main_effect['Pr(>F)'].iloc[0]
                    f_value_sen = main_effect['F'].iloc[0] if 'F' in main_effect.columns else np.nan
                    pes_value_sen = effect_size['pes'].iloc[0] if len(effect_size) > 0 and 'pes' in effect_size.columns else np.nan
                    
                    print(f"     rm-ANOVA på€¼: {p_value_sen:.4f}")
                    
                    # ä¿å­˜å¹´èµ„åˆ†ç»„ç»Ÿè®¡ç»“æœ
                    statistical_results.append({
                        'analysis_type': 'å¹´èµ„åˆ†ç»„',
                        'group': seniority,
                        'n_participants': len(seniority_data),
                        'ai_mean_accuracy': ai_acc.mean(),
                        'ai_std_accuracy': ai_acc.std(ddof=1),
                        'no_ai_mean_accuracy': no_ai_acc.mean(),
                        'no_ai_std_accuracy': no_ai_acc.std(ddof=1),
                        'mean_difference': seniority_data['difference'].mean(),
                        'f_value': f_value_sen,
                        'p_value': p_value_sen,
                        'partial_eta_squared': pes_value_sen,
                        'statistical_method': 'RM-ANOVA',
                        'significance': 'Yes' if p_value_sen < 0.05 else 'No'
                    })
                else:
                    print(f"     rm-ANOVAåˆ†æå¤±è´¥")
                    # ä¿å­˜å¤±è´¥è®°å½•
                    statistical_results.append({
                        'analysis_type': 'å¹´èµ„åˆ†ç»„',
                        'group': seniority,
                        'n_participants': len(seniority_data),
                        'ai_mean_accuracy': ai_acc.mean(),
                        'ai_std_accuracy': ai_acc.std(ddof=1),
                        'no_ai_mean_accuracy': no_ai_acc.mean(),
                        'no_ai_std_accuracy': no_ai_acc.std(ddof=1),
                        'mean_difference': seniority_data['difference'].mean(),
                        'f_value': np.nan,
                        'p_value': np.nan,
                        'partial_eta_squared': np.nan,
                        'statistical_method': 'RM-ANOVA',
                        'significance': 'Failed'
                    })
            else:
                print(f"     rm-ANOVAåˆ†æå¤±è´¥")
                # ä¿å­˜å¤±è´¥è®°å½•
                statistical_results.append({
                    'analysis_type': 'å¹´èµ„åˆ†ç»„',
                    'group': seniority,
                    'n_participants': len(seniority_data),
                    'ai_mean_accuracy': ai_acc.mean(),
                    'ai_std_accuracy': ai_acc.std(ddof=1),
                    'no_ai_mean_accuracy': no_ai_acc.mean(),
                    'no_ai_std_accuracy': no_ai_acc.std(ddof=1),
                    'mean_difference': seniority_data['difference'].mean(),
                    'f_value': np.nan,
                    'p_value': np.nan,
                    'partial_eta_squared': np.nan,
                    'statistical_method': 'RM-ANOVA',
                    'significance': 'Failed'
                })
        else:
            print(f"   {seniority}: æ ·æœ¬é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡æ£€éªŒ")
    
    return paired_df, pd.DataFrame(statistical_results)

def generate_xy_summary_report(ai_metrics, paired_df, output_dir):
    """ç”ŸæˆXYä¸“é¡¹åˆ†ææ€»ç»“æŠ¥å‘Š"""
    print("\nğŸ“ ç”ŸæˆXYä¸“é¡¹åˆ†ææŠ¥å‘Š:")
    print("=" * 40)
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    paired_df.to_csv(f'{output_dir}/xy_nephrology_paired_performance.csv', 
                     index=False, encoding='utf-8-sig')
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    with open(f'{output_dir}/xy_nephrology_analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write("=== XY-Nephrologyä¸“é¡¹åˆ†ææŠ¥å‘Š ===\n\n")
        
        f.write("## æ•°æ®è´¨é‡è¯´æ˜\n")
        f.write("XY-Nephrology (å¾å·ç¬¬ä¸€äººæ°‘åŒ»é™¢è‚¾å†…ç§‘) è¢«é€‰ä¸ºä¸»è¦åˆ†æå¯¹è±¡çš„åŸå› ï¼š\n")
        f.write("1. æ ·æœ¬é‡å……è¶³ï¼š8ä½åŒ»ç”Ÿï¼Œæ˜¯ä¸‰ä¸ªæ•°æ®é›†ä¸­æœ€å¤§çš„\n")
        f.write("2. å¹´èµ„åˆ†å¸ƒå‡è¡¡ï¼šé«˜å¹´èµ„5ä½ï¼Œä½å¹´èµ„3ä½\n")
        f.write("3. AIæ¨¡å‹è¡¨ç°æœ€ä½³ï¼šå‡†ç¡®ç‡80%ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ•°æ®é›†\n")
        f.write("4. æ•°æ®å®Œæ•´æ€§å¥½ï¼šå¯è®¡ç®—å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡\n\n")
        
        f.write("## å…¶ä»–æ•°æ®é›†çš„å±€é™æ€§\n")
        f.write("BC-Obstetricsé—®é¢˜ï¼š\n")
        f.write("- æ ·æœ¬é‡è¿‡å°ï¼ˆä»…3ä½åŒ»ç”Ÿï¼‰ï¼Œç»Ÿè®¡åŠŸæ•ˆä¸è¶³\n")
        f.write("- éš¾ä»¥è¿›è¡Œå¯é çš„ç»Ÿè®¡æ¨æ–­\n\n")
        
        f.write("BS-Nephrologyé—®é¢˜ï¼š\n")
        f.write("- å¹´èµ„åˆ†å¸ƒæä¸å‡è¡¡ï¼ˆ80%ä¸ºä½å¹´èµ„åŒ»ç”Ÿï¼‰\n")
        f.write("- AIè¾…åŠ©æ•ˆæœå·®ï¼Œå‡†ç¡®ç‡ä¸‹é™28%\n")
        f.write("- å¯èƒ½å­˜åœ¨ç»éªŒä¸è¶³å¯¼è‡´çš„è¯„ä¼°åå·®\n\n")
        
        f.write("## AIæ¨¡å‹åŸºå‡†æ€§èƒ½\n")
        f.write(f"- æ•°æ®é›†ï¼šå¾åŒ»è‚¾å†…ç§‘ï¼ˆ10ä¸ªæ¡ˆä¾‹ï¼‰\n")
        f.write(f"- æœ€ä¼˜é˜ˆå€¼ï¼š{ai_metrics['threshold']:.1f}\n")
        f.write(f"- å‡†ç¡®ç‡ï¼š{ai_metrics['accuracy']:.1%}\n")
        f.write(f"- ç²¾ç¡®ç‡ï¼š{ai_metrics['precision']:.1%}\n")
        f.write(f"- å¬å›ç‡ï¼š{ai_metrics['recall']:.1%}\n")
        f.write(f"- ç‰¹å¼‚æ€§ï¼š{ai_metrics['specificity']:.1%}\n")
        f.write(f"- AUROCï¼š{ai_metrics['auroc']:.3f}\n")
        f.write(f"- AUPRCï¼š{ai_metrics['auprc']:.3f}\n\n")
        
        f.write("## åŒ»ç”Ÿæ€§èƒ½åˆ†æ\n")
        f.write(f"- å‚ä¸åŒ»ç”Ÿæ•°ï¼š{len(paired_df)}\n")
        f.write(f"- AIè¾…åŠ©å‡†ç¡®ç‡ï¼š{paired_df['ai_accuracy'].mean():.1%} Â± {paired_df['ai_accuracy'].std(ddof=1):.1%}\n")
        f.write(f"- æ— è¾…åŠ©å‡†ç¡®ç‡ï¼š{paired_df['no_ai_accuracy'].mean():.1%} Â± {paired_df['no_ai_accuracy'].std(ddof=1):.1%}\n")
        f.write(f"- å¹³å‡æå‡ï¼š{paired_df['difference'].mean():+.1%}\n")
        
        # ç»Ÿè®¡æ£€éªŒ
        if len(paired_df) > 1:
            f.write(f"- åˆ†ææ–¹æ³•ï¼šrm-ANOVAï¼ˆé‡å¤æµ‹é‡æ–¹å·®åˆ†æï¼‰\n")
            f.write(f"- ç»Ÿè®¡æ˜¾è‘—æ€§ï¼šè¯¦è§åˆ†æè¾“å‡º\n\n")
        
        f.write("## å¹´èµ„åˆ†ç»„åˆ†æ\n")
        for seniority in ['é«˜å¹´èµ„', 'ä½å¹´èµ„']:
            seniority_data = paired_df[paired_df['seniority'] == seniority]
            if len(seniority_data) > 0:
                f.write(f"\n### {seniority}åŒ»ç”Ÿ (n={len(seniority_data)})\n")
                f.write(f"- AIè¾…åŠ©ï¼š{seniority_data['ai_accuracy'].mean():.1%} Â± {seniority_data['ai_accuracy'].std(ddof=1):.1%}\n")
                f.write(f"- æ— è¾…åŠ©ï¼š{seniority_data['no_ai_accuracy'].mean():.1%} Â± {seniority_data['no_ai_accuracy'].std(ddof=1):.1%}\n")
                f.write(f"- æå‡ï¼š{seniority_data['difference'].mean():+.1%}\n")
                
                if len(seniority_data) > 1:
                    f.write(f"- åˆ†ææ–¹æ³•ï¼šrm-ANOVA\n")
        
        f.write(f"\n## ç»“è®º\n")
        f.write("åŸºäºXY-Nephrologyé«˜è´¨é‡æ•°æ®é›†çš„åˆ†ææ˜¾ç¤ºï¼š\n")
        f.write("1. AIæ¨¡å‹åœ¨ESRDæ­»äº¡é£é™©é¢„æµ‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆ80%å‡†ç¡®ç‡ï¼‰\n")
        f.write(f"2. AIè¾…åŠ©å¯¹åŒ»ç”Ÿè¯Šæ–­å‡†ç¡®ç‡çš„å½±å“ï¼šå¹³å‡{paired_df['difference'].mean():+.1%}\n")
        f.write("3. è¯¥æ•°æ®é›†æä¾›äº†æœ€å¯é çš„AIè¾…åŠ©æ•ˆæœè¯„ä¼°\n")
        f.write("4. ç›¸æ¯”å…¶ä»–æ•°æ®é›†ï¼ŒXYæ•°æ®è´¨é‡æœ€é«˜ï¼Œç»“è®ºæœ€å¯ä¿¡\n")
    
    print("âœ“ XYä¸“é¡¹åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹XY-Nephrologyä¸“é¡¹åˆ†æ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'results/rq2_performance_analysis'
    
    # 1. è§£é‡Šæ•°æ®è´¨é‡é€‰æ‹©ç†ç”±
    explain_data_quality_rationale()
    
    # 2. åˆ†æå‚ä¸è€…ä¿¡æ¯
    xy_participants = analyze_xy_participants()
    
    # 3. AIæ¨¡å‹åŸºå‡†æ€§èƒ½
    ai_metrics = calculate_ai_model_performance_xy()
    
    # 4. æå–åŒ»ç”Ÿè¯„ä¼°æ•°æ®
    clinician_df, xy_participants = extract_xy_clinician_data()
    
    # 5. åˆ†é…AIæ¡ä»¶
    condition_df = assign_ai_conditions_xy(xy_participants, clinician_df)
    
    # 6. è®¡ç®—ä¸ªä½“æ€§èƒ½
    individual_performance_df = calculate_xy_individual_performance(condition_df)
    
    # 7. ç»Ÿè®¡åˆ†æ
    paired_df, statistical_results_df = perform_xy_statistical_analysis(individual_performance_df)
    
    # 8. ç”ŸæˆæŠ¥å‘Š
    generate_xy_summary_report(ai_metrics, paired_df, output_dir)
    
    # 9. ä¿å­˜ä¸ªä½“æ€§èƒ½æ•°æ®
    individual_performance_df.to_csv(f'{output_dir}/xy_nephrology_individual_performance.csv', 
                                   index=False, encoding='utf-8-sig')
    
    # 10. ä¿å­˜ç»Ÿè®¡ç»“æœ
    statistical_results_df.to_csv(f'{output_dir}/xy_nephrology_statistical_results.csv',
                                 index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ XY-Nephrologyä¸“é¡¹åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}/")
    print("   - xy_nephrology_analysis_report.txt (è¯¦ç»†åˆ†ææŠ¥å‘Š)")
    print("   - xy_nephrology_paired_performance.csv (é…å¯¹æ€§èƒ½æ•°æ®)")
    print("   - xy_nephrology_individual_performance.csv (ä¸ªä½“æ€§èƒ½æ•°æ®)")
    print("   - xy_nephrology_statistical_results.csv (ç»Ÿè®¡æ£€éªŒç»“æœ)")
    
    # æ˜¾ç¤ºå…³é”®ç»“æœ
    print(f"\nğŸ“Š å…³é”®å‘ç°:")
    print(f"   AIæ¨¡å‹åŸºå‡†å‡†ç¡®ç‡: {ai_metrics['accuracy']:.1%}")
    print(f"   åŒ»ç”ŸAIè¾…åŠ©å‡†ç¡®ç‡: {paired_df['ai_accuracy'].mean():.1%}")
    print(f"   åŒ»ç”Ÿæ— è¾…åŠ©å‡†ç¡®ç‡: {paired_df['no_ai_accuracy'].mean():.1%}")
    print(f"   AIè¾…åŠ©æ•ˆæœ: {paired_df['difference'].mean():+.1%}")
    
    # rm-ANOVAç»Ÿè®¡æ£€éªŒ
    if len(paired_df) > 1:
        # å‡†å¤‡é•¿æ ¼å¼æ•°æ®
        long_data = []
        for _, row in paired_df.iterrows():
            long_data.append({'participant_id': row['participant_id'], 'condition': 'AIè¾…åŠ©', 'accuracy': row['ai_accuracy']})
            long_data.append({'participant_id': row['participant_id'], 'condition': 'æ— è¾…åŠ©', 'accuracy': row['no_ai_accuracy']})
        
        long_df = pd.DataFrame(long_data)
        
        # æ‰§è¡Œrm-ANOVA
        rm_results = perform_rm_anova_analysis(
            long_df,
            participant_col='participant_id',
            condition_col='condition',
            dv_col='accuracy'
        )
        
        if rm_results:
            main_effect = rm_results.get('main_effect', pd.DataFrame())
            if len(main_effect) > 0 and 'Pr(>F)' in main_effect.columns:
                p_value = main_effect['Pr(>F)'].iloc[0]
                significance = "æ˜¾è‘—" if p_value < 0.05 else "ä¸æ˜¾è‘—"
                print(f"   ç»Ÿè®¡æ˜¾è‘—æ€§: {significance} (rm-ANOVA p={p_value:.4f})")
            else:
                print(f"   rm-ANOVAåˆ†ææ— ç»“æœ")
        else:
            print(f"   rm-ANOVAåˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()